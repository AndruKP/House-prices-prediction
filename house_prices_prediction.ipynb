{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество пропущенных значенний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum() / (df.shape[0])*100 #процент пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки без целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['target'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очищаем целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_format(target):\n",
    "    target = re.sub('[^0-9]', '', target) #оставляем только цифры\n",
    "    target = int(target)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].apply(target_format)\n",
    "df['target'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очищаем признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразовываем в действительные числа\n",
    "def features_float_format(feature):\n",
    "    if feature == 0:\n",
    "        return feature\n",
    "    feature = re.sub('1 1/2', '1.5', feature) # заменяем 1 1/2 на 1.5 (признак stories)\n",
    "    feature = re.sub('[^0-9,\\.]', '', feature) # оставляем только цифры\n",
    "    feature = re.sub(',', '.', feature) # заменяем ',' на '.'\n",
    "    \n",
    "    try:\n",
    "        feature = float(feature)\n",
    "    #если feature - пустая строка, возвращаем 0\n",
    "    except:\n",
    "        feature = 0\n",
    "    return feature\n",
    "# Преобразовываем статус\n",
    "def status_format(status):\n",
    "    status = status.lower()\n",
    "    # если дом ещё не сделан,оставляем только 'coming soon', дату удаляем\n",
    "    if status.startswith('coming soon'): \n",
    "        status = 'coming soon'\n",
    "        \n",
    "    status = re.sub('[^a-z]', ' ', status) # оставляем только буквы\n",
    "    status = re.sub(r'\\b\\w{,2}\\b', '', status) # удаляем сочетание из 1 и 2 букв\n",
    "    status = re.sub(r'\\s+', '', status) # заменяем 1 или более пробелов на ''\n",
    "    if status == 'active' or status == 'for sale': # бóльшая часть домов - for sale или active\n",
    "        status = 1\n",
    "    else:\n",
    "        status = 0\n",
    "    return status\n",
    "#Преобразовываем фичу камина\n",
    "def fireplace_format(fireplace):\n",
    "    if fireplace == 0:\n",
    "        return fireplace\n",
    "    fireplace = fireplace.lower()\n",
    "    \n",
    "    if fireplace.count('no')>0:\n",
    "        fireplace = 0\n",
    "    else:\n",
    "        fireplace = 1\n",
    "    return fireplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_features = ['status','state']  \n",
    "drop_features = ['street', 'mls-id', 'MlsId', 'schools', 'homeFacts', 'city', 'zipcode'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приблизительно 80% домов - ```for sale``` или ```for sale```, поэтому вместо них ставим ```1```, иначе ```0```\n",
    "(заполняем пропуски на пустые строки, и применяем ```status_format```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df['status'].fillna('')\n",
    "df['status'] = df['status'].apply(status_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Property Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.propertyType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приблизительно 50% домов - ```single family```, поэтому оставляем только этот признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propertyType_format(propertyType):\n",
    "    propertyType = propertyType.lower()\n",
    "    propertyType = re.sub('[^a-z]', ' ', propertyType)# оставляем только буквы\n",
    "    \n",
    "    # если начинается на 'single family' - ставим 1, иначе 0\n",
    "    if propertyType.startswith('single family'): \n",
    "        propertyType = 1 \n",
    "    else:\n",
    "        propertyType = 0\n",
    "    return propertyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['propertyType'] = df['propertyType'].fillna('')\n",
    "df['propertyType'] = df['propertyType'].apply(propertyType_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Private pool\n",
    "Вместо пропусков ставим ```no```, заполняем вместо ```yes``` - 1, вместо ```no``` - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['private pool'] = df['private pool'].fillna('no')\n",
    "df['private pool'] = df['private pool'].apply(lambda pool: 1 if pool.lower() == 'yes' else 0)\n",
    "\n",
    "df['PrivatePool'] = df['PrivatePool'].fillna('no')\n",
    "df['PrivatePool'] = df['PrivatePool'].apply(lambda pool: 1 if pool.lower() == 'yes' else 0)\n",
    "\n",
    "df['PrivatePool'] = df['private pool'] | df['PrivatePool']\n",
    "df.drop(['private pool'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baths, sqft, beds, stories, fireplace\n",
    "Заполняем пропуски нулями\n",
    "К ```Baths, sqft, beds, stories``` применяем ```features_float_format```, а к ```fireplace``` - ```fireplace_format```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['baths'] = df['baths'].fillna(0)\n",
    "df['baths'] = df['baths'].apply(features_float_format)\n",
    "\n",
    "df['sqft'] = df['sqft'].fillna(0)\n",
    "df['sqft'] = df['sqft'].apply(features_float_format)\n",
    "\n",
    "df['beds'] = df['beds'].fillna(0)\n",
    "df['beds'] = df['beds'].apply(features_float_format)\n",
    "\n",
    "df['stories'] = df['stories'].fillna(0)\n",
    "df['stories'] = df['stories'].apply(features_float_format)\n",
    "\n",
    "df['fireplace'] = df['fireplace'].fillna(0)\n",
    "df['fireplace'] = df['fireplace'].apply(fireplace_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['homeFacts'] = df['homeFacts'].apply(eval) # конвертируем строку в словарь, используя eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужное нам значение хранится в первом словаре, который хранится в списке, который, в свою очередь, хранится в словаре с ключом ```atAGlanceFacts```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df['homeFacts'][0]\n",
    "print(M,'\\n')\n",
    "print(M['atAGlanceFacts'],'\\n')\n",
    "print(M['atAGlanceFacts'][0],'\\n')\n",
    "print(M['atAGlanceFacts'][0]['factValue'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homeFacts_format(homeFacts):\n",
    "    # если homeFacts - непустой словарь, берём значение 'atAGlanceFacts', иначе 0\n",
    "    homeFacts = homeFacts.get('atAGlanceFacts', 0) \n",
    "    if homeFacts == 0: \n",
    "        return 0\n",
    "    # берём первый елемент списка\n",
    "    homeFacts = homeFacts[0]\n",
    "    # если словарь не пуст, то берем значение\n",
    "    if homeFacts.get('factLabel') == 'Year built':\n",
    "        homeFacts = homeFacts.get('factValue')\n",
    "    # если homeFacts - число, то выводим его, иначе 0\n",
    "    try:\n",
    "        homeFacts = int(homeFacts)\n",
    "    except:\n",
    "        homeFacts = 0\n",
    "    return homeFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yearBuilt'] = df['homeFacts'].apply(homeFacts_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schools rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['schools'] = df['schools'].apply(eval) # конвертируем строку в словарь, используя eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список с рейтингами школ хранится в словаре, который хранится в списке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df['schools'][0]\n",
    "print(M,'\\n')\n",
    "print(M[0],'\\n')\n",
    "print(M[0]['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_format(schools):\n",
    "    # если schools - непустой словарь, берём значение 'rating', иначе 0\n",
    "    schools = schools[0]\n",
    "    schools = schools.get('rating', 0)\n",
    "    if schools == 0: \n",
    "        return 0\n",
    "    \n",
    "    rating = []\n",
    "    for x in schools:\n",
    "        x = re.sub('/10','',x) # если рейтинг записан в формате 'x/10', заменяем на 'x'\n",
    "        rating.append(features_float_format(x)) # с помощью features_float_format превращаем x в число\n",
    "    # ищем среднее арифметическое рейтингов\n",
    "    return np.mean(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем ```rating_format```, если результат - ```nan```, заменяем на ```0```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['schools'].apply(rating_format)\n",
    "df['rating'] = df['rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "По аналогии с ```rating```, выбираем значение из списка словарей и ищем среднее арифметическое расстояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_format(schools):\n",
    "    # если schools - непустой словарь, берём значение 'data', иначе 0\n",
    "    schools = schools[0]\n",
    "    schools = schools.get('data', 0)\n",
    "    if schools == 0: \n",
    "        return 0\n",
    "    # если schools - непустой словарь, берём значение 'distance', иначе 0\n",
    "    schools = schools.get('Distance', 0)\n",
    "    if schools == 0: \n",
    "        return 0\n",
    "    \n",
    "    distance=[]\n",
    "    for x in schools:\n",
    "        distance.append(features_float_format(x)) # с помощью features_float_format превращаем x в число\n",
    "    # ищем среднее арифметическое расстояний\n",
    "    return np.mean(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем ```distance_format``` и заполняем пропуски нулями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['distance'] = df['schools'].apply(distance_format)\n",
    "df['distance'] = df['distance'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем ненужные фичи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State \n",
    "Штат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['state'])], axis=1)\n",
    "df.drop('state', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистический анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "cmap = sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"5pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"8pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '8pt')])\n",
    "]\n",
    "\n",
    "corr.style.background_gradient(cmap, axis=1)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_caption(\"Hover to magify\")\\\n",
    "    .set_precision(2)\\\n",
    "    .set_table_styles(magnify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(df['target']+1),bins = 'auto')\n",
    "plt.title('log of target')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(df['sqft']+1),bins = 20)\n",
    "plt.title('log of area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(df['beds']+1),bins = 25)\n",
    "plt.title('log of beds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(df['stories']+1),bins = 15)\n",
    "plt.title('log of stories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(df['rating'],bins = 10)\n",
    "plt.title('rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(df['distance']+1),bins = 'auto')\n",
    "plt.title('log of distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['target'].sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['rating'],df['target'])\n",
    "\n",
    "plt.title('rating/target')\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['distance'],df['target'])\n",
    "\n",
    "plt.xlim(-2,80)\n",
    "plt.ylim(-100,1e8)\n",
    "\n",
    "plt.title('distance/target')\n",
    "plt.xlabel('distance')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['stories'],df['target'])\n",
    "plt.xlim(-5,105)\n",
    "plt.ylim(-10,1e7*8)\n",
    "\n",
    "plt.title('stories/target')\n",
    "plt.xlabel('stories')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['beds'],df['target'])\n",
    "\n",
    "plt.xlim(-5,105)\n",
    "plt.ylim(-10,1e7*8)\n",
    "\n",
    "plt.title('beds/target')\n",
    "plt.xlabel('beds')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['yearBuilt'],df['target'])\n",
    "\n",
    "plt.xlim(1650,2050)\n",
    "plt.ylim(-50,8*1e7)\n",
    "\n",
    "plt.title('yearBuilt/target')\n",
    "plt.xlabel('yearBuilt')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(df['sqft'],df['target'])\n",
    "\n",
    "plt.xlim(500,0.25*1e5)\n",
    "plt.ylim(-1000,3*1e7)\n",
    "\n",
    "plt.title('area/target')\n",
    "plt.xlabel('area')\n",
    "plt.ylabel('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающаю и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('target', axis = 1), df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем функцию для оценки точности предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    train_predict = clf.predict(X_train)\n",
    "    test_predict = clf.predict(X_test)\n",
    "    \n",
    "    print('train mse :', mean_squared_error(y_train, train_predict) )\n",
    "    print('test mse  :', mean_squared_error(y_test, test_predict) )\n",
    "    \n",
    "    print('train rmse :', np.sqrt(mean_squared_error(y_train, train_predict) ))\n",
    "    print('test rmse  :',np.sqrt(mean_squared_error(y_test, test_predict) ))\n",
    "    #Coefficient of determination\n",
    "    print('train R^2', clf.score(X_train,y_train)) \n",
    "    print('test R^2', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(lr,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент детерминации ниже 0.1, а значит модель очень плохо предсказывает результат. Попробуем различные деревья решений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```max_depth```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tree_max_depth = trial.suggest_int('tree_max_depth', 5, 10)\n",
    "    \n",
    "    tree = DecisionTreeRegressor(max_depth  = tree_max_depth, random_state = 42)\n",
    "    tree.fit(X_train,y_train)\n",
    "\n",
    "    test_predict = tree.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог: при максимальной глубине меньше 7 модель недообучается, а при максимальной глубине больше 7 - переобучается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth  = 7 ,random_state = 42)\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(tree,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем различные ансамбли:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```n_estimators```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    bagging_n_estimators = trial.suggest_int(\"rf_n_estimators\", 5, 19)\n",
    "    \n",
    "    bagging_trees = BaggingRegressor(tree, n_estimators = bagging_n_estimators)\n",
    "    bagging_trees.fit(X_train,y_train)\n",
    "\n",
    "    test_predict = bagging_trees.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bagging_trees = BaggingRegressor(tree, n_estimators = 19)\n",
    "bagging_trees.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(bagging_trees,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```n_estimators``` и  ```max_depth```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 5, 10)\n",
    "    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 8, 13)\n",
    "    \n",
    "    random_forest = RandomForestRegressor(n_estimators = rf_n_estimators, max_depth = rf_max_depth, random_state = 42)\n",
    "    random_forest.fit(X_train,y_train)\n",
    "\n",
    "    test_predict = random_forest.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators = 13, max_depth = 10, random_state = 42)\n",
    "random_forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(random_forest,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```n_estimators``` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    ada_n_estimators = trial.suggest_int(\"ada_n_estimators\", 5, 10)\n",
    "    \n",
    "    adaboost = AdaBoostRegressor(tree,n_estimators = ada_n_estimators, random_state = 42)\n",
    "    adaboost.fit(X_train,y_train)\n",
    "\n",
    "    test_predict = adaboost.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor(tree,n_estimators = 6, random_state = 42)\n",
    "adaboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(adaboost,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```n_estimators, max_depth, min_samples_split```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    gb_max_depth = trial.suggest_int('gb_max_depth', 5, 10)\n",
    "    gb_n_estimators = trial.suggest_int('gb_n_estimators', 8, 20)\n",
    "    gb_min_samples_split = trial.suggest_int('gb_min_samples_split', 2, 5)\n",
    "    \n",
    "    gradientboosting = GradientBoostingRegressor(n_estimators = gb_n_estimators, \n",
    "                                                 max_depth = gb_max_depth,\n",
    "                                                 min_samples_split = gb_min_samples_split,\n",
    "                                                 loss = 'ls')\n",
    "\n",
    "    gradientboosting.fit(X_train, y_train)\n",
    "    test_predict = gradientboosting.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientboosting = GradientBoostingRegressor(n_estimators = 20, max_depth = 12, min_samples_split = 4,loss = 'ls')\n",
    "gradientboosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gradientboosting,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```optune``` переберём различные варианты ```n_estimators, max_depth```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    xgb_max_depth = trial.suggest_int('xgb_max_depth', 5, 10)\n",
    "    xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 8, 125)\n",
    "    model = xgb.XGBRegressor(max_depth = xgb_max_depth, \n",
    "                                 n_estimators = xgb_n_estimators,\n",
    "                                 seed = 42) \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, test_predict)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(max_depth = 6,\n",
    "                                 n_estimators = 90,\n",
    "                                 seed = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог:\n",
    "Было построено несколько моделей для предсказания цены дома, в том числе с исользованием библиотеки XGBoost. Эту модель мы и попробуем загрузить как прототип:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl','wb') as output:\n",
    "    pickle.dump(model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
